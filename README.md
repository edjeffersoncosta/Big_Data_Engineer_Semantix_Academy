# Big_Data_Engineer_Semantix_Academy
Seja bem vindo(a) ao treinamento de Big Data Engineer no Semantix Academy,

## Trilha de Estudo:

## Big Data Foundations (Semana 1, 2 e 3)
* Conhecimento de ferramentas atuais no mercado de Big Data;
* Criação e funcionamento de um cluster Hadoop para Big Data em Docker;
* Manipulação de dados com HDFS;  
* Manipulação de dados com uso do Hive;
* Otimização de consultas em grandes volumes de dados estruturados e semiestruturados com uso de Hive;
* Ingestão de dados relacionais para o HDFS/Hive, com uso do Sqoop;
* Otimização de importação no Sqoop;
* Exportação de dados do HDFS para o SGBD, com uso do Sqoop;
* Manipulação de dados com HBase;
* Operações com Dataframe em Spark para processamento de dados em batch;
* Uso do Spark SQL Queries para consultas de dados estruturados e semiestruturados.

## MongoDB - Básico (Semana 4)
* Entendimento de conceitos e arquitetura NoSQL e MongoDB;
* Instalação de cluster MongoDB através de container e Cloud;
* Manipular coleções, documentos e índices;
* Realizar diversas pesquisas no MongoDB com diferentes operadores;
* Fazer uso das interfaces gráficas MongoExpress e MongoCompass;
* Trabalhar com pipeline de agregações;
* ntendimento de Replicação e shards.

## Redis – Básico (Semana 5)
* Entendimento de conceitos e arquitetura NoSQL e Redis;
* Instalação de cluster Redis através de container;
* Manipulação de diversos tipos de estrutura de dados com Redis-CLI;
* mplementar paradigma de mensagens Pub/Sub;
* Configurações básicas de persistência de dados.

* Apache Kafka – Básico (Semana 6)
* Entendimento de conceitos e arquitetura do Kafka e da Confluent;
* Instalação de cluster Kafka através de container;
* Gerenciamento de tópicos;
* Produção e consumo de dados através do console;
* Entendimento das guias do Control Center;
* Desenvolvimento de stream com uso do KSQL;
* Aplicação de KSQL Datagen;
* Produção e consumo de dados com uso do Schema Registry;
vTrabalhando com Kafka Connect;
* Custos com Confluent Cloud;
* Otimização de parâmetros;
* Melhores práticas em um cluster Kafka.

## Elastic Essential I (Semana 7 e 8):
* Entendimento de conceitos e arquitetura da Elastic;
* Instalação de cluster Elastic através de container;
* Realizar operações de CRUD em índices;
* Gerenciamento de índices;
* Alteração de mapeamento e reindex;
* Desenvolvimento de consultas do tipo term, terms, range, match e multi_match, com uso de bool query;
* Aplicação de analyzers em atributos;
* Desenvolvimento de agregações básicas;
* Ingestão de dados através de beats e logstash;
* Entendimento das guias do Kibana;

## Spark - Big Data Processing (Semana 9, 10 e 11)
* Uso do Jupyter Notebooks para a criação de projetos em Spark com Python
* Spark batch intermediario
* Operações com RDD em Spark para processamento de dados em batch;
* Uso de Partições com RDD;
* Operações com Dataset em Spark para processamento de dados em batch;
* Uso de Dataset em Dataframe e RDD;
* Comandos avançados com Dataset;
* Uso do IntelliJ IDEA para a criação de projetos em Spark com Scala;
* Struct Streaming para leitura de dados do Kafka;
* Spark Streaming para leitura de dados do Kafka;
* Otimizações com uso de Variáveis Compartilhadas;
* Criações de User defined Function;
* Configurações de Tunning para o Spark Application.

# Muito Obrigado Prof Rodrigo Augusto Rebouças e Semantix Academy
